{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7e68d4d",
   "metadata": {},
   "source": [
    "## Install Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21c1c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[m\u001b[1m\u001b[32m  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[m\u001b[1m\u001b[31mâ–’â–ˆâ–ˆâ–€â–ˆâ–ˆâ–ˆ \u001b[m\u001b[1m\u001b[33m â–“â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ \u001b[m\u001b[1m\u001b[36mâ–„â–„â–„  \u001b[m\u001b[1m\u001b[35m     â–ˆâ–ˆ â–„â–ˆâ–€    \u001b[m\u001b[1m\u001b[32m Hostname: Freak-PC \u001b[m\n",
      "  \u001b[m\u001b[1m\u001b[32mâ–“â–ˆâ–ˆ   \u001b[m\u001b[1m\u001b[31mâ–’â–“â–ˆâ–ˆ â–’ â–ˆâ–ˆ\u001b[m\u001b[1m\u001b[33mâ–’â–“â–ˆ   â–€\u001b[m\u001b[1m\u001b[36mâ–’â–ˆâ–ˆâ–ˆâ–ˆâ–„   \u001b[m\u001b[1m\u001b[35m  â–ˆâ–ˆâ–„â–ˆâ–’     \u001b[m\n",
      "  \u001b[m\u001b[1m\u001b[32mâ–’â–ˆâ–ˆâ–ˆâ–ˆ \u001b[m\u001b[1m\u001b[31mâ–‘â–“â–ˆâ–ˆ â–‘â–„â–ˆ\u001b[m\u001b[1m\u001b[33m â–’â–’â–ˆâ–ˆâ–ˆ  \u001b[m\u001b[1m\u001b[36mâ–’â–ˆâ–ˆ  â–€â–ˆâ–„ \u001b[m\u001b[1m\u001b[35m â–“â–ˆâ–ˆâ–ˆâ–„â–‘     \u001b[m\u001b[1m\u001b[31m OS: EndeavourOS \u001b[m\n",
      "  \u001b[m\u001b[1m\u001b[32mâ–‘â–“â–ˆâ–’  \u001b[m\u001b[1m\u001b[31mâ–‘â–’â–ˆâ–ˆâ–€â–€â–ˆâ–„\u001b[m\u001b[1m\u001b[33m  â–’â–“â–ˆ  â–„\u001b[m\u001b[1m\u001b[36mâ–‘â–ˆâ–ˆâ–„â–„â–„â–„â–ˆâ–ˆ \u001b[m\u001b[1m\u001b[35mâ–“â–ˆâ–ˆ â–ˆâ–„     \u001b[m\n",
      "  \u001b[m\u001b[1m\u001b[32mâ–‘â–’â–ˆâ–‘ \u001b[m\u001b[1m\u001b[31m  â–‘â–ˆâ–ˆâ–“ â–’â–ˆâ–ˆâ–’\u001b[m\u001b[1m\u001b[33mâ–‘â–’â–ˆâ–ˆâ–ˆâ–ˆ\u001b[m\u001b[1m\u001b[36mâ–’â–“â–ˆ   â–“â–ˆâ–ˆ\u001b[m\u001b[1m\u001b[35mâ–’â–’â–ˆâ–ˆâ–’ â–ˆâ–„    \u001b[m\u001b[1m\u001b[33m User: Freak \u001b[m\n",
      "  \u001b[m\u001b[1m\u001b[32mâ–’ â–‘   \u001b[m\u001b[1m\u001b[31mâ–‘ â–’â–“ â–‘â–’â–“â–‘â–‘\u001b[m\u001b[1m\u001b[33mâ–‘ â–’â–‘ â–‘\u001b[m\u001b[1m\u001b[36mâ–’â–’   â–“â–’â–ˆâ–‘\u001b[m\u001b[1m\u001b[35mâ–’ â–’â–’ â–“â–’     \u001b[m\n",
      "  \u001b[m\u001b[1m\u001b[32m â–‘       \u001b[m\u001b[1m\u001b[31mâ–‘â–’ â–‘ â–’â–‘ \u001b[m\u001b[1m\u001b[33mâ–‘ â–‘  \u001b[m\u001b[1m\u001b[36mâ–‘ â–’   â–’â–’ \u001b[m\u001b[1m\u001b[35mâ–‘â–‘ â–‘â–’ â–’â–‘    \u001b[m\u001b[1m\u001b[36m Date: 09 June 2025 \u001b[m\n",
      "  \u001b[m\u001b[1m\u001b[32m â–‘ â–‘    \u001b[m\u001b[1m\u001b[31m â–‘â–‘   â–‘    \u001b[m\u001b[1m\u001b[33mâ–‘    \u001b[m\u001b[1m\u001b[36mâ–‘   â–’   \u001b[m\u001b[1m\u001b[35mâ–‘ â–‘â–‘ â–‘     \u001b[m\n",
      "  \u001b[m\u001b[1m\u001b[32m        \u001b[m\u001b[1m\u001b[31m  â–‘        \u001b[m\u001b[1m\u001b[33mâ–‘  \u001b[m\u001b[1m\u001b[36mâ–‘     â–‘  \u001b[m\u001b[1m\u001b[35mâ–‘â–‘  â–‘       \u001b[m\n",
      "\n",
      "\u001b[2mResolved \u001b[1m281 packages\u001b[0m \u001b[2min 0.62ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m269 packages\u001b[0m \u001b[2min 0.06ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add crewai crewai_tools duckduckgo-search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ccca03",
   "metadata": {},
   "source": [
    "### Import Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "409341bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Crew, Process, Task, LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4578359",
   "metadata": {},
   "source": [
    "### Create Custom Tools for Duck Duck Go Searcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "046a0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai.tools import BaseTool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class DDGSearchInput(BaseModel):\n",
    "    \"\"\"Defines the Input schema for Duck Duck Go Tool\"\"\"\n",
    "    query: str = Field(\"Input query for searching the web using Duck Duck Go Tool\")\n",
    "\n",
    "class DDGSearchTool(BaseTool):\n",
    "    name: str = \"DuckDuckGo Search Tool\"\n",
    "    description: str = \"Search the web for a given query.\"\n",
    "    args_schema: type[BaseModel] = DDGSearchInput\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        duckduckgo_tool = DuckDuckGoSearchRun()\n",
    "        response = duckduckgo_tool.invoke(query)\n",
    "        return response\n",
    "\n",
    "    def _get_tool(self):\n",
    "        return DDGSearchTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43da02c1",
   "metadata": {},
   "source": [
    "### Create Crew Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1363e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trending_company_finder = Agent(\n",
    "        role=\"Financial News Analyst that finds trending Indian companies in {sector}\",\n",
    "        goal=\"\"\"You read the latest Indian news, then find 2-3 companies in Indian Stock Market that are trending in the news for further research.\n",
    "            Always pick new companies. Don't pick the same company twice.\"\"\",\n",
    "        backstory=\"\"\"You are a market expert with a knack for picking out the most interesting companies based on latest news.\n",
    "            You spot multiple companies that are trending in the news.\"\"\",\n",
    "        verbose=True,\n",
    "        llm=LLM(model=\"ollama/qwen3:1.7b\", base_url=\"http://localhost:11434\"),\n",
    "        tools=[DDGSearchTool()]\n",
    "    )\n",
    "\n",
    "financial_researcher = Agent(\n",
    "        role=\"Senior Financial Researcher\",\n",
    "        goal=\"\"\"Given details of trending companies in the news, you provide comprehensive analysis of each in a report.\"\"\",\n",
    "        backstory=\"\"\"You are a financial expert with a proven track record of deeply analyzing hot companies and building comprehensive reports.\"\"\",\n",
    "        verbose=True,\n",
    "        llm=LLM(model=\"ollama/qwen3:1.7b\", base_url=\"http://localhost:11434\"),\n",
    "        tools=[DDGSearchTool()]\n",
    "    )\n",
    "\n",
    "stock_picker = Agent(\n",
    "        role=\"Stock Picker from Research\",\n",
    "        goal=\"\"\"Given a list of researched companies with investment potential, you select the best one for investment,\n",
    "            notifying the user and then providing a detailed report. Don't pick the same company twice.\"\"\",\n",
    "        backstory=\"\"\"You're a meticulous, skilled financial analyst with a proven track record of equity selection.\n",
    "            You have a talent for synthesizing research and picking the best company for investment.\"\"\",\n",
    "        verbose=True,\n",
    "        llm=LLM(model=\"ollama/qwen3:1.7b\", base_url=\"http://localhost:11434\"),\n",
    "    )\n",
    "\n",
    "manager = Agent(\n",
    "        role=\"Manager\",\n",
    "        goal=\"\"\"You are a skilled project manager who can delegate tasks in order to achieve your goal, which is to pick the best company for investment.\"\"\",\n",
    "        backstory=\"\"\"You are an experienced and highly effective project manager who can delegate tasks to the right people.\"\"\",\n",
    "        verbose=True,\n",
    "        llm=LLM(model=\"ollama/qwen3:1.7b\", base_url=\"http://localhost:11434\"),\n",
    "        allow_delegation=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5077bc7",
   "metadata": {},
   "source": [
    "### Structured Output Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61fb51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class TrendingCompany(BaseModel):\n",
    "    \"\"\" A company that is in the news and attracting attention \"\"\"\n",
    "    name: str = Field(description=\"Company name\")\n",
    "    ticker: str = Field(description=\"Stock ticker symbol\")\n",
    "    reason: str = Field(description=\"Reason this company is trending in the news\")\n",
    "\n",
    "class TrendingCompanyList(BaseModel):\n",
    "    \"\"\" List of multiple trending companies that are in the news \"\"\"\n",
    "    companies: List[TrendingCompany] = Field(description=\"List of companies trending in the news\")\n",
    "\n",
    "class TrendingCompanyResearch(BaseModel):\n",
    "    \"\"\" Detailed research on a company \"\"\"\n",
    "    name: str = Field(description=\"Company name\")\n",
    "    market_position: str = Field(description=\"Current market position and competitive analysis\")\n",
    "    future_outlook: str = Field(description=\"Future outlook and growth prospects\")\n",
    "    investment_potential: str = Field(description=\"Investment potential and suitability for investment\")\n",
    "\n",
    "class TrendingCompanyResearchList(BaseModel):\n",
    "    \"\"\" A list of detailed research on all the companies \"\"\"\n",
    "    research_list: List[TrendingCompanyResearch] = Field(description=\"Comprehensive research on all trending companies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b645b59",
   "metadata": {},
   "source": [
    "### Create Crew Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df16cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_trending_companies = Task(\n",
    "        description=\"\"\"Find the top trending companies in the news in {sector} by searching the latest news. Find new companies that you've not found before.\"\"\",\n",
    "        expected_output=\"\"\"A list of trending companies in {sector}\"\"\",\n",
    "        agent=trending_company_finder,\n",
    "        output_pydantic=TrendingCompanyList,\n",
    "        output_file=\"output/trending-companies.json\"\n",
    "    )\n",
    "\n",
    "research_trending_companies = Task(\n",
    "        description=\"\"\"Given a list of trending companies, provide detailed analysis of each company in a report by searching online\"\"\",\n",
    "        expected_output=\"\"\"A report containing detailed analysis of each company\"\"\",\n",
    "        agent=financial_researcher,\n",
    "        output_pydantic=TrendingCompanyResearchList,\n",
    "        output_file=\"output/trending-companies-research.json\",\n",
    "        context=[find_trending_companies]\n",
    "    )\n",
    "\n",
    "pick_best_company = Task(\n",
    "        description=\"\"\"Analyze the research findings and pick the best company for investment.\n",
    "            Send a push notification to the user with the decision and 1 sentence rationale.\n",
    "            Then respond with a detailed report on why you chose this company, and which companies were not selected.\"\"\",\n",
    "        expected_output=\"\"\"The chosen company and why it was chosen; the companies that were not selected and why they were not selected.\"\"\",\n",
    "        agent=stock_picker,\n",
    "        output_file=\"output/picked-stock-decision.md\",\n",
    "        context=[research_trending_companies]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e729c0b7",
   "metadata": {},
   "source": [
    "### Create Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f9f837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew =  Crew(\n",
    "        agents=[trending_company_finder, financial_researcher, stock_picker],\n",
    "        tasks=[find_trending_companies, research_trending_companies, pick_best_company],\n",
    "        process=Process.hierarchical,\n",
    "        verbose=True,\n",
    "        manager_agent=manager\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc01784f",
   "metadata": {},
   "source": [
    "### Run Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b95d6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Crew Execution Started â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">3917b574-e140-492c-9c56-4f51d8513642</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">â”‚</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36mâ•­â”€\u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[36mâ”€â•®\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36m3917b574-e140-492c-9c56-4f51d8513642\u001b[0m                                                                       \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ”‚\u001b[0m                                                                                                                 \u001b[36mâ”‚\u001b[0m\n",
       "\u001b[36mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸš€ Crew: crew</span>\n",
       "â””â”€â”€ <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ğŸ“‹ Task: fb215a0e-a72b-4350-a19d-ed4bc880f0ac</span>\n",
       "    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   Status: </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">Executing Task...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mğŸš€ Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
       "â””â”€â”€ \u001b[1;33mğŸ“‹ Task: fb215a0e-a72b-4350-a19d-ed4bc880f0ac\u001b[0m\n",
       "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸš€ Crew: crew</span>\n",
       "â””â”€â”€ <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ğŸ“‹ Task: fb215a0e-a72b-4350-a19d-ed4bc880f0ac</span>\n",
       "    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   Status: </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">Executing Task...</span>\n",
       "    â””â”€â”€ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ğŸ¤– Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Manager</span>\n",
       "        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    Status: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">In Progress</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mğŸš€ Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
       "â””â”€â”€ \u001b[1;33mğŸ“‹ Task: fb215a0e-a72b-4350-a19d-ed4bc880f0ac\u001b[0m\n",
       "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
       "    â””â”€â”€ \u001b[1;32mğŸ¤– Agent: \u001b[0m\u001b[32mManager\u001b[0m\n",
       "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mManager\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mFind the top trending companies in the news in Finance by searching the latest news. Find new companies that you've not found before.\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ğŸ¤– Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Manager</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    Status: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">In Progress</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mğŸ¤– Agent: \u001b[0m\u001b[32mManager\u001b[0m\n",
       "\u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mManager\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92m<think>\n",
      "Okay, the user wants to find the top trending companies in Finance by searching the latest news and identify any new companies they haven't found before. Let me figure out how to approach this.\n",
      "First, I need to use the DuckDuckGo Search Tool to search for the latest news in Finance. The query should be something like \"latest trending finance companies\" or \"top financial news companies\". I'll use that tool to get the current information.\n",
      "Once I have the search results, I need to analyze the news articles to find the trending companies. The user mentioned that the final answer should be a list of companies with their names, tickers, and reasons. So, I need to extract those details from the search results.\n",
      "However, since I can't directly access the web, I'll have to simulate the search and then delegate the task to the Financial News Analyst coworker. The coworker can help parse the news articles and extract the required information. I'll use the Delegate work to coworker tool with the task to analyze the search results and extract the companies.\n",
      "After getting the list from the coworker, I'll compile the information into the required JSON format. The final answer should include all the companies with their names, tickers, and reasons. I need to make sure that the answer is complete and meets the user's criteria.\n",
      "</think>\n",
      "Thought: I need to search for the latest financial news to find trending companies and delegate the analysis to the Financial News Analyst.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mDuckDuckGo Search Tool\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"query\\\": \\\"latest trending finance companies\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "Detailed info and reviews on 55 top Finance companies and startups in Pune in 2025. Get the latest updates on their products, jobs, funding, investors, founders and more. ... We are creating a \" Payments Hub\" solution, in a modular way, to help Banks manage the increasing trend of digital transactions, brought about by ever increasing payments ... 10 Critical Fintech Trends; 20 Trending Personal Finance Startups; 15 Digital Payment Startups; From processing payments to financial services, these are the top fintech companies and startups right now: 1. Sunbit. 5-year search growth: 669%. Search growth status: Exploding. CEO: Arad Levertov. Year founded: 2016. Location: Los Angeles, California The open banking revolution presents significant opportunities for financial innovation and collaboration. CFOs must explore how open banking and APIs can enhance financial operations, improve cash management and streamline payment processes. This trend also opens new revenue streams and partnerships, transforming traditional business models. Zone & Company makes fintech software products used by enterprise finance teams as add-on integrations to Oracle NetSuite. Its billing tool, ZoneBilling, connects to NetSuite enterprise resource planning products and offers features that manage billing scenarios like recurring subscriptions, usage-based licenses, service fees, inventory, price tiering and other complex contracts. Circle is a leading financial technology company that enables seamless digital currency payments and blockchain-powered financial solutions. As the creator of USD Coin (USDC), one of the world's leading stablecoins, Circle empowers businesses to transact efficiently, securely, and at scale, unlocking global commerce and financial services.\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ğŸ¤– Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Manager</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    Status: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">In Progress</span>\n",
       "â””â”€â”€ <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">ğŸ§  </span><span style=\"color: #000080; text-decoration-color: #000080\">Thinking...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mğŸ¤– Agent: \u001b[0m\u001b[32mManager\u001b[0m\n",
       "\u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
       "â””â”€â”€ \u001b[1;34mğŸ§  \u001b[0m\u001b[34mThinking...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸš€ Crew: crew</span>\n",
       "â””â”€â”€ <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ğŸ“‹ Task: fb215a0e-a72b-4350-a19d-ed4bc880f0ac</span>\n",
       "    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   Status: </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">Executing Task...</span>\n",
       "    â””â”€â”€ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ğŸ¤– Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Manager</span>\n",
       "        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    Status: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">In Progress</span>\n",
       "        â””â”€â”€ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">âŒ LLM Failed</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mğŸš€ Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
       "â””â”€â”€ \u001b[1;33mğŸ“‹ Task: fb215a0e-a72b-4350-a19d-ed4bc880f0ac\u001b[0m\n",
       "    \u001b[37m   Status: \u001b[0m\u001b[2;33mExecuting Task...\u001b[0m\n",
       "    â””â”€â”€ \u001b[1;32mğŸ¤– Agent: \u001b[0m\u001b[32mManager\u001b[0m\n",
       "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
       "        â””â”€â”€ \u001b[1;31mâŒ LLM Failed\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM Error â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">âŒ LLM Call Failed</span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Error: </span><span style=\"color: #800000; text-decoration-color: #800000\">litellm.APIConnectionError: list index out of range</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">Traceback (most recent call last):</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/main.py\", line </span>   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">2870, in completion</span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">    response = base_llm_http_handler.completion(</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">  File \"/home/freak/Trainings/AI-ML/09.Agentic </span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">AI/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 269, in completion</span>  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">    data = provider_config.transform_request(</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">  File \"/home/freak/Trainings/AI-ML/09.Agentic </span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">AI/.venv/lib/python3.12/site-packages/litellm/llms/ollama/completion/transformation.py\", line 322, in </span>         <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">transform_request</span>                                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">    modified_prompt = ollama_pt(model=model, messages=messages)</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">  File \"/home/freak/Trainings/AI-ML/09.Agentic </span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">AI/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/prompt_templates/factory.py\", line 229, in </span>   <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">ollama_pt</span>                                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">    tool_calls = messages[msg_i].get(\"tool_calls\")</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">                 ~~~~~~~~^^^^^^^</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000\">IndexError: list index out of range</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m LLM Error \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[1;31mâŒ LLM Call Failed\u001b[0m                                                                                             \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[37mError: \u001b[0m\u001b[31mlitellm.APIConnectionError: list index out of range\u001b[0m                                                     \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31mTraceback (most recent call last):\u001b[0m                                                                             \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/main.py\", line \u001b[0m   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m2870, in completion\u001b[0m                                                                                            \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m    response = base_llm_http_handler.completion(\u001b[0m                                                               \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m                                                               \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m  File \"/home/freak/Trainings/AI-ML/09.Agentic \u001b[0m                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31mAI/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 269, in completion\u001b[0m  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m    data = provider_config.transform_request(\u001b[0m                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m  File \"/home/freak/Trainings/AI-ML/09.Agentic \u001b[0m                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31mAI/.venv/lib/python3.12/site-packages/litellm/llms/ollama/completion/transformation.py\", line 322, in \u001b[0m         \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31mtransform_request\u001b[0m                                                                                              \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m    modified_prompt = ollama_pt(model=model, messages=messages)\u001b[0m                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m  File \"/home/freak/Trainings/AI-ML/09.Agentic \u001b[0m                                                                \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31mAI/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/prompt_templates/factory.py\", line 229, in \u001b[0m   \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31mollama_pt\u001b[0m                                                                                                      \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m    tool_calls = messages[msg_i].get(\"tool_calls\")\u001b[0m                                                             \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31m                 ~~~~~~~~^^^^^^^\u001b[0m                                                                               \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[31mIndexError: list index out of range\u001b[0m                                                                            \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.APIConnectionError: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/main.py\", line 2870, in completion\n",
      "    response = base_llm_http_handler.completion(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 269, in completion\n",
      "    data = provider_config.transform_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/ollama/completion/transformation.py\", line 322, in transform_request\n",
      "    modified_prompt = ollama_pt(model=model, messages=messages)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/prompt_templates/factory.py\", line 229, in ollama_pt\n",
      "    tool_calls = messages[msg_i].get(\"tool_calls\")\n",
      "                 ~~~~~~~~^^^^^^^\n",
      "IndexError: list index out of range\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m Error during LLM call: litellm.APIConnectionError: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/main.py\", line 2870, in completion\n",
      "    response = base_llm_http_handler.completion(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 269, in completion\n",
      "    data = provider_config.transform_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/ollama/completion/transformation.py\", line 322, in transform_request\n",
      "    modified_prompt = ollama_pt(model=model, messages=messages)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/prompt_templates/factory.py\", line 229, in ollama_pt\n",
      "    tool_calls = messages[msg_i].get(\"tool_calls\")\n",
      "                 ~~~~~~~~^^^^^^^\n",
      "IndexError: list index out of range\n",
      "\u001b[00m\n",
      "\u001b[91m An unknown error occurred. Please check the details below.\u001b[00m\n",
      "\u001b[91m Error details: litellm.APIConnectionError: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/main.py\", line 2870, in completion\n",
      "    response = base_llm_http_handler.completion(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 269, in completion\n",
      "    data = provider_config.transform_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/ollama/completion/transformation.py\", line 322, in transform_request\n",
      "    modified_prompt = ollama_pt(model=model, messages=messages)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/prompt_templates/factory.py\", line 229, in ollama_pt\n",
      "    tool_calls = messages[msg_i].get(\"tool_calls\")\n",
      "                 ~~~~~~~~^^^^^^^\n",
      "IndexError: list index out of range\n",
      "\u001b[00m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">ğŸš€ Crew: crew</span>\n",
       "â””â”€â”€ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ğŸ“‹ Task: fb215a0e-a72b-4350-a19d-ed4bc880f0ac</span>\n",
       "    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   Assigned to: </span><span style=\"color: #800000; text-decoration-color: #800000\">Manager</span>\n",
       "    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   Status: </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">âŒ Failed</span>\n",
       "    â””â”€â”€ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ğŸ¤– Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Manager</span>\n",
       "        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    Status: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">In Progress</span>\n",
       "        â””â”€â”€ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">âŒ LLM Failed</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mğŸš€ Crew: \u001b[0m\u001b[1;36mcrew\u001b[0m\n",
       "â””â”€â”€ \u001b[1;31mğŸ“‹ Task: fb215a0e-a72b-4350-a19d-ed4bc880f0ac\u001b[0m\n",
       "    \u001b[37m   Assigned to: \u001b[0m\u001b[31mManager\u001b[0m\n",
       "    \u001b[37m   Status: \u001b[0m\u001b[1;31mâŒ Failed\u001b[0m\n",
       "    â””â”€â”€ \u001b[1;32mğŸ¤– Agent: \u001b[0m\u001b[32mManager\u001b[0m\n",
       "        \u001b[37m    Status: \u001b[0m\u001b[1;32mIn Progress\u001b[0m\n",
       "        â””â”€â”€ \u001b[1;31mâŒ LLM Failed\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Task Failure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Task Failed</span>                                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #800000; text-decoration-color: #800000\">fb215a0e-a72b-4350-a19d-ed4bc880f0ac</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #800000; text-decoration-color: #800000\">Manager</span>                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m Task Failure \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[1;31mTask Failed\u001b[0m                                                                                                    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31mfb215a0e-a72b-4350-a19d-ed4bc880f0ac\u001b[0m                                                                     \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[31mManager\u001b[0m                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Crew Failure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Crew Execution Failed</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #800000; text-decoration-color: #800000\">crew</span>                                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #800000; text-decoration-color: #800000\">3917b574-e140-492c-9c56-4f51d8513642</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m Crew Failure \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[1;31mCrew Execution Failed\u001b[0m                                                                                          \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[37mName: \u001b[0m\u001b[31mcrew\u001b[0m                                                                                                     \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m  \u001b[37mID: \u001b[0m\u001b[31m3917b574-e140-492c-9c56-4f51d8513642\u001b[0m                                                                       \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                                 \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "APIConnectionError",
     "evalue": "litellm.APIConnectionError: list index out of range\nTraceback (most recent call last):\n  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/main.py\", line 2870, in completion\n    response = base_llm_http_handler.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 269, in completion\n    data = provider_config.transform_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/ollama/completion/transformation.py\", line 322, in transform_request\n    modified_prompt = ollama_pt(model=model, messages=messages)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/prompt_templates/factory.py\", line 229, in ollama_pt\n    tool_calls = messages[msg_i].get(\"tool_calls\")\n                 ~~~~~~~~^^^^^^^\nIndexError: list index out of range\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/main.py:2870\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   2864\u001b[39m     api_base = (\n\u001b[32m   2865\u001b[39m         litellm.api_base\n\u001b[32m   2866\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m api_base\n\u001b[32m   2867\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m get_secret(\u001b[33m\"\u001b[39m\u001b[33mOLLAMA_API_BASE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2868\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:11434\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2869\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2870\u001b[39m     response = \u001b[43mbase_llm_http_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2874\u001b[39m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2877\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2878\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mollama\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# model call logging done inside the class as we make need to modify I/O to fit aleph alpha's requirements\u001b[39;49;00m\n\u001b[32m   2885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2886\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2888\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33mollama_chat\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py:269\u001b[39m, in \u001b[36mBaseLLMHTTPHandler.completion\u001b[39m\u001b[34m(self, model, messages, api_base, custom_llm_provider, model_response, encoding, logging_obj, optional_params, timeout, litellm_params, acompletion, stream, fake_stream, api_key, headers, client, provider_config)\u001b[39m\n\u001b[32m    260\u001b[39m api_base = provider_config.get_complete_url(\n\u001b[32m    261\u001b[39m     api_base=api_base,\n\u001b[32m    262\u001b[39m     api_key=api_key,\n\u001b[32m   (...)\u001b[39m\u001b[32m    266\u001b[39m     litellm_params=litellm_params,\n\u001b[32m    267\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m data = \u001b[43mprovider_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/ollama/completion/transformation.py:322\u001b[39m, in \u001b[36mOllamaConfig.transform_request\u001b[39m\u001b[34m(self, model, messages, optional_params, litellm_params, headers)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# handle `/chat/completions` requests\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     modified_prompt = \u001b[43mollama_pt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modified_prompt, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/prompt_templates/factory.py:229\u001b[39m, in \u001b[36mollama_pt\u001b[39m\u001b[34m(model, messages)\u001b[39m\n\u001b[32m    227\u001b[39m msg_i += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m tool_calls = \u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmsg_i\u001b[49m\u001b[43m]\u001b[49m.get(\u001b[33m\"\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    230\u001b[39m ollama_tool_calls = []\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAPIConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Markdown\n\u001b[32m      2\u001b[39m inputs = {\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msector\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mFinance\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m result = \u001b[43mcrew\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/crew.py:651\u001b[39m, in \u001b[36mCrew.kickoff\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    649\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._run_sequential_process()\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.hierarchical:\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_hierarchical_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    653\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    654\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe process \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.process\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not implemented yet.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    655\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/crew.py:766\u001b[39m, in \u001b[36mCrew._run_hierarchical_process\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Creates and assigns a manager agent to make sure the crew completes the tasks.\"\"\"\u001b[39;00m\n\u001b[32m    765\u001b[39m \u001b[38;5;28mself\u001b[39m._create_manager_agent()\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/crew.py:864\u001b[39m, in \u001b[36mCrew._execute_tasks\u001b[39m\u001b[34m(self, tasks, start_index, was_replayed)\u001b[39m\n\u001b[32m    861\u001b[39m     futures.clear()\n\u001b[32m    863\u001b[39m context = \u001b[38;5;28mself\u001b[39m._get_context(task, task_outputs)\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m task_output = \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mList\u001b[49m\u001b[43m[\u001b[49m\u001b[43mBaseTool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools_for_task\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    869\u001b[39m task_outputs.append(task_output)\n\u001b[32m    870\u001b[39m \u001b[38;5;28mself\u001b[39m._process_task_result(task, task_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/task.py:347\u001b[39m, in \u001b[36mTask.execute_sync\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_sync\u001b[39m(\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    342\u001b[39m     agent: Optional[BaseAgent] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    343\u001b[39m     context: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    344\u001b[39m     tools: Optional[List[BaseTool]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    345\u001b[39m ) -> TaskOutput:\n\u001b[32m    346\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/task.py:491\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    489\u001b[39m \u001b[38;5;28mself\u001b[39m.end_time = datetime.datetime.now()\n\u001b[32m    490\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskFailedEvent(error=\u001b[38;5;28mstr\u001b[39m(e), task=\u001b[38;5;28mself\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/task.py:411\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;28mself\u001b[39m.processed_by_agents.add(agent.role)\n\u001b[32m    410\u001b[39m crewai_event_bus.emit(\u001b[38;5;28mself\u001b[39m, TaskStartedEvent(context=context, task=\u001b[38;5;28mself\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    417\u001b[39m pydantic_output, json_output = \u001b[38;5;28mself\u001b[39m._export_output(result)\n\u001b[32m    418\u001b[39m task_output = TaskOutput(\n\u001b[32m    419\u001b[39m     name=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    420\u001b[39m     description=\u001b[38;5;28mself\u001b[39m.description,\n\u001b[32m   (...)\u001b[39m\u001b[32m    426\u001b[39m     output_format=\u001b[38;5;28mself\u001b[39m._get_output_format(),\n\u001b[32m    427\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/agent.py:319\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m e.\u001b[34m__class__\u001b[39m.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m\"\u001b[39m\u001b[33mlitellm\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    310\u001b[39m     \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[32m    311\u001b[39m     crewai_event_bus.emit(\n\u001b[32m    312\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    313\u001b[39m         event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    317\u001b[39m         ),\n\u001b[32m    318\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    320\u001b[39m \u001b[38;5;28mself\u001b[39m._times_executed += \u001b[32m1\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._times_executed > \u001b[38;5;28mself\u001b[39m.max_retry_limit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/agent.py:295\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    293\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._execute_with_timeout(task_prompt, task, \u001b[38;5;28mself\u001b[39m.max_execution_time)\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_without_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# Propagate TimeoutError without retry\u001b[39;00m\n\u001b[32m    299\u001b[39m     crewai_event_bus.emit(\n\u001b[32m    300\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    301\u001b[39m         event=AgentExecutionErrorEvent(\n\u001b[32m   (...)\u001b[39m\u001b[32m    305\u001b[39m         ),\n\u001b[32m    306\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/agent.py:399\u001b[39m, in \u001b[36mAgent._execute_without_timeout\u001b[39m\u001b[34m(self, task_prompt, task)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_without_timeout\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    387\u001b[39m     task_prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    388\u001b[39m     task: Task\n\u001b[32m    389\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    390\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute a task without a timeout.\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m    392\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m \u001b[33;03m        The output of the agent.\u001b[39;00m\n\u001b[32m    398\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_names\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magent_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mask_for_human_input\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhuman_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:123\u001b[39m, in \u001b[36mCrewAgentExecutor.invoke\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    120\u001b[39m handle_unknown_error(\u001b[38;5;28mself\u001b[39m._printer, e)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m e.\u001b[34m__class__\u001b[39m.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m\"\u001b[39m\u001b[33mlitellm\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:112\u001b[39m, in \u001b[36mCrewAgentExecutor.invoke\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28mself\u001b[39m.ask_for_human_input = \u001b[38;5;28mbool\u001b[39m(inputs.get(\u001b[33m\"\u001b[39m\u001b[33mask_for_human_input\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     formatted_answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mself\u001b[39m._printer.print(\n\u001b[32m    115\u001b[39m         content=\u001b[33m\"\u001b[39m\u001b[33mAgent failed to reach a final answer. This is likely a bug - please report it.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    116\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    117\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:208\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.\u001b[34m__class__\u001b[39m.\u001b[34m__module__\u001b[39m.startswith(\u001b[33m\"\u001b[39m\u001b[33mlitellm\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_context_length_exceeded(e):\n\u001b[32m    210\u001b[39m         handle_context_length(\n\u001b[32m    211\u001b[39m             respect_context_window=\u001b[38;5;28mself\u001b[39m.respect_context_window,\n\u001b[32m    212\u001b[39m             printer=\u001b[38;5;28mself\u001b[39m._printer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    216\u001b[39m             i18n=\u001b[38;5;28mself\u001b[39m._i18n,\n\u001b[32m    217\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:155\u001b[39m, in \u001b[36mCrewAgentExecutor._invoke_loop\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    144\u001b[39m     formatted_answer = handle_max_iterations_exceeded(\n\u001b[32m    145\u001b[39m         formatted_answer,\n\u001b[32m    146\u001b[39m         printer=\u001b[38;5;28mself\u001b[39m._printer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    150\u001b[39m         callbacks=\u001b[38;5;28mself\u001b[39m.callbacks,\n\u001b[32m    151\u001b[39m     )\n\u001b[32m    153\u001b[39m enforce_rpm_limit(\u001b[38;5;28mself\u001b[39m.request_within_rpm_limit)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m answer = \u001b[43mget_llm_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprinter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_printer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m formatted_answer = process_llm_response(answer, \u001b[38;5;28mself\u001b[39m.use_stop_words)\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_answer, AgentAction):\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Extract agent fingerprint if available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/utilities/agent_utils.py:156\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m     printer.print(\n\u001b[32m    153\u001b[39m         content=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    154\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    155\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n\u001b[32m    158\u001b[39m     printer.print(\n\u001b[32m    159\u001b[39m         content=\u001b[33m\"\u001b[39m\u001b[33mReceived None or empty response from LLM call.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    160\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    161\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/utilities/agent_utils.py:147\u001b[39m, in \u001b[36mget_llm_response\u001b[39m\u001b[34m(llm, messages, callbacks, printer)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     answer = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m     printer.print(\n\u001b[32m    153\u001b[39m         content=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    154\u001b[39m         color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    155\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/llm.py:888\u001b[39m, in \u001b[36mLLM.call\u001b[39m\u001b[34m(self, messages, tools, callbacks, available_functions)\u001b[39m\n\u001b[32m    884\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._handle_streaming_response(\n\u001b[32m    885\u001b[39m             params, callbacks, available_functions\n\u001b[32m    886\u001b[39m         )\n\u001b[32m    887\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m888\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_non_streaming_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavailable_functions\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m LLMContextLengthExceededException:\n\u001b[32m    893\u001b[39m     \u001b[38;5;66;03m# Re-raise LLMContextLengthExceededException as it should be handled\u001b[39;00m\n\u001b[32m    894\u001b[39m     \u001b[38;5;66;03m# by the CrewAgentExecutor._invoke_loop method, which can then decide\u001b[39;00m\n\u001b[32m    895\u001b[39m     \u001b[38;5;66;03m# whether to summarize the content or abort based on the respect_context_window flag\u001b[39;00m\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/crewai/llm.py:727\u001b[39m, in \u001b[36mLLM._handle_non_streaming_response\u001b[39m\u001b[34m(self, params, callbacks, available_functions)\u001b[39m\n\u001b[32m    721\u001b[39m \u001b[38;5;66;03m# --- 1) Make the completion call\u001b[39;00m\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    723\u001b[39m     \u001b[38;5;66;03m# Attempt to make the completion call, but catch context window errors\u001b[39;00m\n\u001b[32m    724\u001b[39m     \u001b[38;5;66;03m# and convert them to our own exception type for consistent handling\u001b[39;00m\n\u001b[32m    725\u001b[39m     \u001b[38;5;66;03m# across the codebase. This allows CrewAgentExecutor to handle context\u001b[39;00m\n\u001b[32m    726\u001b[39m     \u001b[38;5;66;03m# length issues appropriately.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m     response = \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ContextWindowExceededError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    729\u001b[39m     \u001b[38;5;66;03m# Convert litellm's context window error to our own exception type\u001b[39;00m\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# for consistent handling in the rest of the codebase\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LLMContextLengthExceededException(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/utils.py:1247\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[32m   1244\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1245\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1246\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/utils.py:1125\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1123\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1125\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1126\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/main.py:3182\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, thinking, **kwargs)\u001b[39m\n\u001b[32m   3179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m   3180\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3181\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3182\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3183\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3185\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3188\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2214\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2212\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2213\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2216\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2190\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2183\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(\n\u001b[32m   2184\u001b[39m                 message=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(exception_provider, error_str),\n\u001b[32m   2185\u001b[39m                 llm_provider=custom_llm_provider,\n\u001b[32m   2186\u001b[39m                 model=model,\n\u001b[32m   2187\u001b[39m                 request=original_exception.request,\n\u001b[32m   2188\u001b[39m             )\n\u001b[32m   2189\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2190\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(\n\u001b[32m   2191\u001b[39m                 message=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2192\u001b[39m                     \u001b[38;5;28mstr\u001b[39m(original_exception), traceback.format_exc()\n\u001b[32m   2193\u001b[39m                 ),\n\u001b[32m   2194\u001b[39m                 llm_provider=custom_llm_provider,\n\u001b[32m   2195\u001b[39m                 model=model,\n\u001b[32m   2196\u001b[39m                 request=httpx.Request(\n\u001b[32m   2197\u001b[39m                     method=\u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m, url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2198\u001b[39m                 ),  \u001b[38;5;66;03m# stub the request\u001b[39;00m\n\u001b[32m   2199\u001b[39m             )\n\u001b[32m   2200\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2201\u001b[39m     \u001b[38;5;66;03m# LOGGING\u001b[39;00m\n\u001b[32m   2202\u001b[39m     exception_logging(\n\u001b[32m   2203\u001b[39m         logger_fn=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2204\u001b[39m         additional_args={\n\u001b[32m   (...)\u001b[39m\u001b[32m   2208\u001b[39m         exception=e,\n\u001b[32m   2209\u001b[39m     )\n",
      "\u001b[31mAPIConnectionError\u001b[39m: litellm.APIConnectionError: list index out of range\nTraceback (most recent call last):\n  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/main.py\", line 2870, in completion\n    response = base_llm_http_handler.completion(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 269, in completion\n    data = provider_config.transform_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/llms/ollama/completion/transformation.py\", line 322, in transform_request\n    modified_prompt = ollama_pt(model=model, messages=messages)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/freak/Trainings/AI-ML/09.Agentic AI/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/prompt_templates/factory.py\", line 229, in ollama_pt\n    tool_calls = messages[msg_i].get(\"tool_calls\")\n                 ~~~~~~~~^^^^^^^\nIndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "inputs = {\n",
    "    'sector': 'Finance',\n",
    "}\n",
    "\n",
    "result = crew.kickoff(inputs=inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02664dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your final answer must be the great and the most complete as possible, it must be outcome described.\n",
       "\n",
       "Thought: After conducting thorough research on Apple, focusing on its current company status and health, historical performance, major challenges and opportunities, recent news and events, and future outlook and potential developments, I present to you a comprehensive report on Apple.\n",
       "\n",
       "Executive Summary:\n",
       "Apple is an American multinational technology giant that designs, manufactures, and markets consumer electronics, computer software, and online services. As of 2023, Apple has solidified its position as one of the world's most valuable companies, driven by its innovative products, loyal customer base, and strategic business moves. This report provides an in-depth analysis of Apple's current situation, highlighting key trends, challenges, opportunities, and future outlook.\n",
       "\n",
       "Historical Performance:\n",
       "Apple has experienced significant growth over the years, with annual revenues increasing from $4 billion in 1997 to over $500 billion in 2020. The company's market capitalization has fluctuated, ranging from approximately $2 trillion to over $2.5 trillion. Apple's success can be attributed to its product portfolio, which includes iPhones, Macs, iPads, Apple Watches, and AirPods, as well as services such as iCloud, Apple Music, and Apple TV+. The company's expansion into new markets, including augmented reality (AR) and artificial intelligence (AI), has also contributed to its growth.\n",
       "\n",
       "Major Challenges:\n",
       "Apple faces several challenges that may impact its future performance. Some of the key challenges include:\n",
       "\n",
       "1. Competition from other smartphone manufacturers such as Samsung and Google.\n",
       "2. Increasing regulatory scrutiny in various regions, particularly in China.\n",
       "3. Maintaining market share in a crowded smartphone market.\n",
       "4. Managing supply chain disruptions due to global economic uncertainty.\n",
       "\n",
       "Opportunities:\n",
       "Despite these challenges, Apple has opportunities for growth and innovation. Some of the key opportunities include:\n",
       "\n",
       "1. Expanding into new markets, such as China and India.\n",
       "2. Developing new products and services, such as AR glasses and AI-powered assistants.\n",
       "3. Increasing its presence in emerging industries, such as healthcare and education.\n",
       "\n",
       "Recent News and Events:\n",
       "In recent years, Apple has made several significant announcements that have impacted the company's performance. Some of the key events include:\n",
       "\n",
       "1. The launch of the iPhone 14 series, which featured improved cameras and battery life.\n",
       "2. The introduction of Apple Watch Series 8, with new features such as a always-on display and improved GPS capabilities.\n",
       "3. The announcement of AirPods Pro 2, with enhanced noise-cancellation technology.\n",
       "\n",
       "Future Outlook:\n",
       "Based on current market trends and analyst forecasts, Apple is expected to continue its growth trajectory in the coming years. Some key predictions include:\n",
       "\n",
       "1. Continued expansion into new markets, particularly in emerging regions.\n",
       "2. Increased investment in AR and AI technologies.\n",
       "3. Further integration of services, such as Apple Arcade and Apple News+.\n",
       "\n",
       "Potential Developments:\n",
       "Several factors could impact Apple's future performance, including changes in consumer behavior, technological advancements, and economic trends. Some potential developments include:\n",
       "\n",
       "1. The rise of new competitors in the smartphone market.\n",
       "2. Increased competition from other tech companies, such as Microsoft and Amazon.\n",
       "3. Changes in government regulations and policies affecting the tech industry.\n",
       "\n",
       "Conclusion:\n",
       "In conclusion, Apple is a highly successful technology company with a strong brand presence and innovative products. While it faces several challenges, including competition and regulatory scrutiny, there are also opportunities for growth and innovation. With continued investment in emerging technologies and strategic business moves, Apple is well-positioned to maintain its leadership position in the market.\n",
       "\n",
       "Thought: After conducting thorough research on Apple, focusing on its current company status and health, historical performance, major challenges and opportunities, recent news and events, and future outlook and potential developments, I present to you a comprehensive report on Apple.\n",
       "\n",
       "Note: The final answer is now complete."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(result.raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
