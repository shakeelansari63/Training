{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)\n",
    "SVM is classifier that find optimal hyperplane to maximise margin between two classes.\n",
    "  \n",
    "As shown in below diagram, any of green lines can be used to classify the square classes from circle class. But we have to find an optimal line with is evenly spaced. That is one on right\n",
    "![SVM](img/svm.png)\n",
    "  \n",
    "In 2 Dimension, this classifier will be a line, in 3 dimension it would be plane. Hence we call it hyperplane for n dimensions.\n",
    "![SVM Plane](img/svm_plane.png)\n",
    "\n",
    "## Kernel Trick\n",
    "Kernel trick is process of projecting data to higher dimension for seperation which in current dimension are not seperable.\n",
    "![Kernel Trick](img/kernel_trick.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM: Hyperparameters\n",
    "\n",
    "Import [Support Vector Machines](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) from `sklearn` and explore the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Support Vector Machines Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_proba',\n",
       " '_compute_kernel',\n",
       " '_decision_function',\n",
       " '_dense_decision_function',\n",
       " '_dense_fit',\n",
       " '_dense_predict',\n",
       " '_dense_predict_proba',\n",
       " '_estimator_type',\n",
       " '_get_coef',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_impl',\n",
       " '_more_tags',\n",
       " '_pairwise',\n",
       " '_predict_log_proba',\n",
       " '_predict_proba',\n",
       " '_sparse_decision_function',\n",
       " '_sparse_fit',\n",
       " '_sparse_kernels',\n",
       " '_sparse_predict',\n",
       " '_sparse_predict_proba',\n",
       " '_validate_for_predict',\n",
       " '_validate_targets',\n",
       " '_warn_from_fit_status',\n",
       " 'coef_',\n",
       " 'decision_function',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'n_support_',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'set_params']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Major Hyperparameters for SVM\n",
    "Same as previous we do not try to tune all hyperparameters. Here we will be concerned about 2 major hyperparameters\n",
    "### C $\\to$ Penalty which determine how closely model fit to training data\n",
    "Same as we saw in Logistic Regression.  \n",
    "As $C \\to 0 \\implies $ Lower penalty means higher chance of underfit.  \n",
    "And $C \\to \\infty \\implies $ Higher penalty means higher chance of overfit.  \n",
    "![C in SVM](img/svm_c.png)\n",
    "### kernel $\\to$ Kernel Trick"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
