{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f9199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e51b169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Spark Sessiom\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(\"TestSpark\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv('fakefriends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb80073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c4c1aa0441ff:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TestSpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2f342c47f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "887084db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('fakefriends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58527d77-65be-4361-83fb-31948525e879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+---------------+\n",
      "|_c0|     _c1|_c2|            _c3|\n",
      "+---+--------+---+---------------+\n",
      "| Id|    Name|Age|NumberOfFriends|\n",
      "|  0|    Will| 33|            385|\n",
      "|  1|Jean-Luc| 26|              2|\n",
      "|  2|    Hugh| 55|            221|\n",
      "|  3|  Deanna| 40|            465|\n",
      "|  4|   Quark| 68|             21|\n",
      "|  5|  Weyoun| 59|            318|\n",
      "|  6|  Gowron| 37|            220|\n",
      "|  7|    Will| 54|            307|\n",
      "|  8|  Jadzia| 38|            380|\n",
      "|  9|    Hugh| 27|            181|\n",
      "| 10|     Odo| 53|            191|\n",
      "| 11|     Ben| 57|            372|\n",
      "| 12|   Keiko| 54|            253|\n",
      "| 13|Jean-Luc| 56|            444|\n",
      "| 14|    Hugh| 43|             49|\n",
      "| 15|     Rom| 36|             49|\n",
      "| 16|  Weyoun| 22|            323|\n",
      "| 17|     Odo| 35|             13|\n",
      "| 18|Jean-Luc| 45|            455|\n",
      "+---+--------+---+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show data\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99efa2fb-67d6-4a51-b84f-f8b60ddb9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take header in account\n",
    "df = spark.read.option('header', 'true').csv('fakefriends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "360b4e8a-1b75-4851-bcfb-1bb60ce4e44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id='0', Name='Will', Age='33', NumberOfFriends='385'),\n",
       " Row(Id='1', Name='Jean-Luc', Age='26', NumberOfFriends='2'),\n",
       " Row(Id='2', Name='Hugh', Age='55', NumberOfFriends='221')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94df983d-863d-4b64-953e-61348d10a71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- NumberOfFriends: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See Schema\n",
    "# You will notice by default all are string.\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da25ef2e-1827-48d5-a049-7935ea17133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- NumberOfFriends: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Infer Schema based on Data\n",
    "df = spark.read.option('header', 'true').csv('fakefriends.csv', inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d09d14ba-0f75-4440-bb4d-7a19f2a18db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=0, Name='Will', Age=33, NumberOfFriends=385),\n",
       " Row(Id=1, Name='Jean-Luc', Age=26, NumberOfFriends=2),\n",
       " Row(Id=2, Name='Hugh', Age=55, NumberOfFriends=221)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abe6eb3f-0d12-4d36-9476-e7340b5c94b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- NumberOfFriends: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(Id=0, Name='Will', Age=33, NumberOfFriends=385),\n",
       " Row(Id=1, Name='Jean-Luc', Age=26, NumberOfFriends=2),\n",
       " Row(Id=2, Name='Hugh', Age=55, NumberOfFriends=221)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Header and InferSchema\n",
    "df = spark.read.csv('fakefriends.csv', header=True, inferSchema=True)\n",
    "df.printSchema()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a6ca90-761a-4b23-a668-c72b29910be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id', 'Name', 'Age', 'NumberOfFriends']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf680636-9a1b-4b04-9eca-7d20049cc617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Will', Age=33),\n",
       " Row(Name='Jean-Luc', Age=26),\n",
       " Row(Name='Hugh', Age=55)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only specific column\n",
    "# Select method returns a new data frame\n",
    "df.select(['Name', 'Age']).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbe958d7-ae34-4ffa-b8a5-7bb1c2470b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Id', 'int'), ('Name', 'string'), ('Age', 'int'), ('NumberOfFriends', 'int')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Column data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7427f136-6c78-40c2-9345-d5ff1dfcfb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----+------------------+------------------+\n",
      "|summary|                Id|Name|               Age|   NumberOfFriends|\n",
      "+-------+------------------+----+------------------+------------------+\n",
      "|  count|               503| 502|               501|               502|\n",
      "|   mean|             251.0|null| 43.68263473053892|247.59561752988049|\n",
      "| stddev|145.34785860135676|null|14.860318901164648|147.67316308161114|\n",
      "|    min|                 0|Anil|                18|                 1|\n",
      "|    max|               502|Worf|                69|               499|\n",
      "+-------+------------------+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe Dataframe stats\n",
    "df.describe()\n",
    "\n",
    "# describe method return another dataframe which can be used for show\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98b55864-723b-489b-9e1d-ff67169e3b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=0, Name='Will', Age=33, NumberOfFriends=385, Age after 2 years=35),\n",
       " Row(Id=1, Name='Jean-Luc', Age=26, NumberOfFriends=2, Age after 2 years=28),\n",
       " Row(Id=2, Name='Hugh', Age=55, NumberOfFriends=221, Age after 2 years=57)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column - use WithColumn method\n",
    "df = df.withColumn('Age after 2 years', df['Age'] + 2)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ffe817e-98cd-4a24-986e-f5cd0580fb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=0, Name='Will', Age=33, NumberOfFriends=385),\n",
       " Row(Id=1, Name='Jean-Luc', Age=26, NumberOfFriends=2),\n",
       " Row(Id=2, Name='Hugh', Age=55, NumberOfFriends=221)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the column using drop\n",
    "df = df.drop('Age after 2 years')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2eb859f-084d-4517-8e24-9cb2432ba831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=0, User Name='Will', Age=33, NumberOfFriends=385),\n",
       " Row(Id=1, User Name='Jean-Luc', Age=26, NumberOfFriends=2),\n",
       " Row(Id=2, User Name='Hugh', Age=55, NumberOfFriends=221)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename Column\n",
    "df.withColumnRenamed('Name', 'User Name').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96119b99-648f-4187-9489-6f2d61e48e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=495, Name='Data', Age=46, NumberOfFriends=155),\n",
       " Row(Id=496, Name='Gowron', Age=39, NumberOfFriends=275),\n",
       " Row(Id=497, Name='Lwaxana', Age=34, NumberOfFriends=423),\n",
       " Row(Id=498, Name='Jadzia', Age=62, NumberOfFriends=36),\n",
       " Row(Id=499, Name='Leeta', Age=62, NumberOfFriends=12)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where any value is null\n",
    "df.na.drop().tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9badcbc-f9b5-4a00-92ff-36ba7698df25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=498, Name='Jadzia', Age=62, NumberOfFriends=36),\n",
       " Row(Id=499, Name='Leeta', Age=62, NumberOfFriends=12),\n",
       " Row(Id=500, Name=None, Age=31, NumberOfFriends=12),\n",
       " Row(Id=501, Name='Anil', Age=None, NumberOfFriends=15),\n",
       " Row(Id=502, Name='Suresh', Age=None, NumberOfFriends=None)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where all values are null\n",
    "df.na.drop(how = 'all').tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d60af36-40af-4910-9c24-542fca10816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=498, Name='Jadzia', Age=62, NumberOfFriends=36),\n",
       " Row(Id=499, Name='Leeta', Age=62, NumberOfFriends=12),\n",
       " Row(Id=500, Name=None, Age=31, NumberOfFriends=12),\n",
       " Row(Id=501, Name='Anil', Age=None, NumberOfFriends=15),\n",
       " Row(Id=502, Name='Suresh', Age=None, NumberOfFriends=None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop row if atleast more than 2 null values i.e. threshold is 2\n",
    "df.na.drop(how = 'any', thresh=1).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a18484a-7d1a-4d0e-acbb-e444191a742c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=496, Name='Gowron', Age=39, NumberOfFriends=275),\n",
       " Row(Id=497, Name='Lwaxana', Age=34, NumberOfFriends=423),\n",
       " Row(Id=498, Name='Jadzia', Age=62, NumberOfFriends=36),\n",
       " Row(Id=499, Name='Leeta', Age=62, NumberOfFriends=12),\n",
       " Row(Id=501, Name='Anil', Age=None, NumberOfFriends=15)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop row if there is null in specific column/s\n",
    "df.na.drop(how = 'any', subset=['Name', 'NumberOfFriends']).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4ca8563-4184-4ad1-b725-14f95e781687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=498, Name='Jadzia', Age=62, NumberOfFriends=36),\n",
       " Row(Id=499, Name='Leeta', Age=62, NumberOfFriends=12),\n",
       " Row(Id=500, Name='Misisng', Age=31, NumberOfFriends=12),\n",
       " Row(Id=501, Name='Anil', Age=None, NumberOfFriends=15),\n",
       " Row(Id=502, Name='Suresh', Age=None, NumberOfFriends=None)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling Missing values for String \n",
    "df.na.fill('Misisng', subset=['Name']).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0f7818f-e36e-411c-9363-07eaf1502dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Id=498, Name='Jadzia', Age=62, NumberOfFriends=36, Age_imputed=62, NumberOfFriends_imputed=36),\n",
       " Row(Id=499, Name='Leeta', Age=62, NumberOfFriends=12, Age_imputed=62, NumberOfFriends_imputed=12),\n",
       " Row(Id=500, Name=None, Age=31, NumberOfFriends=12, Age_imputed=31, NumberOfFriends_imputed=12),\n",
       " Row(Id=501, Name='Anil', Age=None, NumberOfFriends=15, Age_imputed=43, NumberOfFriends_imputed=15),\n",
       " Row(Id=502, Name='Suresh', Age=None, NumberOfFriends=None, Age_imputed=43, NumberOfFriends_imputed=247)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use imputer funtion for filling numeric values\n",
    "from pyspark.ml.feature import Imputer\n",
    "imputer = Imputer(\n",
    "    inputCols=['Age', 'NumberOfFriends'],\n",
    "    outputCols=[f\"{colname}_imputed\" for colname in ['Age', 'NumberOfFriends']]\n",
    ").setStrategy(\"mean\") # we can also use median instead of mean\n",
    "\n",
    "# Fit data Frame to Imputer \n",
    "imputer.fit(df).transform(df).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7421303-214f-4225-be3d-978ae0e207a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|    Name|Age|\n",
      "+--------+---+\n",
      "|   Quark| 68|\n",
      "|     Odo| 67|\n",
      "|    Hugh| 67|\n",
      "|   Keiko| 69|\n",
      "|   Dukat| 67|\n",
      "|   Quark| 66|\n",
      "|     Ben| 66|\n",
      "|   Nerys| 69|\n",
      "|   Keiko| 69|\n",
      "|    Morn| 67|\n",
      "|     Ben| 69|\n",
      "|Jean-Luc| 68|\n",
      "|     Rom| 66|\n",
      "|  Gowron| 67|\n",
      "|  Kasidy| 67|\n",
      "|   Nerys| 67|\n",
      "|  Martok| 68|\n",
      "|Jean-Luc| 68|\n",
      "|   Brunt| 67|\n",
      "|    Morn| 69|\n",
      "+--------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter\n",
    "df.filter(\"age > 65\").select(['Name', 'Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c7e1424-3699-46c4-9647-f92586b59047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---------------+\n",
      "| Id|  Name|Age|NumberOfFriends|\n",
      "+---+------+---+---------------+\n",
      "|  4| Quark| 68|             21|\n",
      "| 62| Keiko| 69|              9|\n",
      "|116|   Ben| 69|             75|\n",
      "|233|Gowron| 67|             70|\n",
      "|249| Nerys| 66|             41|\n",
      "|254|  Ezri| 67|             79|\n",
      "|329| Dukat| 67|             35|\n",
      "|354|Kasidy| 69|             15|\n",
      "|396| Keiko| 67|             38|\n",
      "+---+------+---+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenating multiple conditions. Not of denoted by ~\n",
    "df.filter( (df['Age'] > 65) & (df['NumberOfFriends'] < 100)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "634ae403-1507-4c89-b274-a48b6e95cc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|Age|max(NumberOfFriends)|\n",
      "+---+--------------------+\n",
      "| 31|                 481|\n",
      "| 65|                 443|\n",
      "| 53|                 451|\n",
      "| 34|                 423|\n",
      "| 28|                 378|\n",
      "| 26|                 492|\n",
      "| 27|                 471|\n",
      "| 44|                 499|\n",
      "| 22|                 478|\n",
      "| 47|                 488|\n",
      "| 52|                 487|\n",
      "| 40|                 465|\n",
      "| 20|                 384|\n",
      "| 57|                 465|\n",
      "| 54|                 462|\n",
      "| 48|                 439|\n",
      "| 19|                 404|\n",
      "| 64|                 499|\n",
      "| 41|                 397|\n",
      "| 43|                 428|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregations \n",
    "df.select(['Age','NumberOfFriends']).groupBy(['Age']).max('NumberOfFriends').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ccbd6397-c559-4b57-8a82-dfc0ed3c6653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "|Age|count(Age)|sum(NumberOfFriends)|\n",
      "+---+----------+--------------------+\n",
      "| 31|         9|                2150|\n",
      "| 65|         5|                1491|\n",
      "| 53|         7|                1560|\n",
      "| 34|         6|                1473|\n",
      "| 28|        10|                2091|\n",
      "| 26|        17|                4115|\n",
      "| 27|         8|                1825|\n",
      "| 44|        12|                3386|\n",
      "| 22|         7|                1445|\n",
      "| 47|         9|                2099|\n",
      "| 52|        11|                3747|\n",
      "| 40|        17|                4264|\n",
      "| 20|         5|                 825|\n",
      "| 57|        12|                3106|\n",
      "| 54|        13|                3615|\n",
      "| 48|        10|                2814|\n",
      "| 19|        11|                2346|\n",
      "| 64|        12|                3376|\n",
      "| 41|         9|                2417|\n",
      "| 43|         7|                1614|\n",
      "+---+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For multiple different types of aggregation, use agg method\n",
    "df.groupBy(['Age']).agg({'Age': 'count', 'NumberOfFriends': 'sum'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9889f9-160f-4b4b-85f0-78a25d8b566b",
   "metadata": {},
   "source": [
    "## MLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f2733cb-c60a-4679-8834-f44874300051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets read some data\n",
    "df_spark = spark.read.csv('EmployeeSalaries.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "204ea741-c182-40b5-9434-5aeac75228ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+----------+--------+\n",
      "|   Name|Age|Sex|Experience|  Salary|\n",
      "+-------+---+---+----------+--------+\n",
      "|   Ajit| 22|  M|         2| 20000.0|\n",
      "|  Sumit| 34|  M|        12|100000.0|\n",
      "|   Anil| 54|  M|        22|200000.0|\n",
      "| Zubair| 27|  M|         5| 40000.0|\n",
      "|Shubham| 39|  M|        12| 50000.0|\n",
      "|   Neha| 26|  F|         4| 30000.0|\n",
      "|  Kapil| 36|  M|        13| 80000.0|\n",
      "| Prachi| 28|  F|         6| 47000.0|\n",
      "+-------+---+---+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95395a0c-1e5c-467d-8478-40009d20703a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed: Output column Sex_index already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68/3048008056.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf_spark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_spark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_spark\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise TypeError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1310\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: Output column Sex_index already exists."
     ]
    }
   ],
   "source": [
    "# Convert Categorifal features to numeric for\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "categorical_cols = ['Sex']\n",
    "\n",
    "indexer = StringIndexer(\n",
    "    inputCols=categorical_cols,\n",
    "    outputCols=[f\"{col}_index\" for col in categorical_cols]\n",
    ")\n",
    "\n",
    "df_spark = indexer.fit(df_spark).transform(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b71aa687-0b69-497f-bb5a-910a4cae06a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+--------+---+\n",
      "|   Name|Age|Experience|  Salary|Sex|\n",
      "+-------+---+----------+--------+---+\n",
      "|   Ajit| 22|         2| 20000.0|0.0|\n",
      "|  Sumit| 34|        12|100000.0|0.0|\n",
      "|   Anil| 54|        22|200000.0|0.0|\n",
      "| Zubair| 27|         5| 40000.0|0.0|\n",
      "|Shubham| 39|        12| 50000.0|0.0|\n",
      "|   Neha| 26|         4| 30000.0|1.0|\n",
      "|  Kapil| 36|        13| 80000.0|0.0|\n",
      "| Prachi| 28|         6| 47000.0|1.0|\n",
      "+-------+---+----------+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename Sex column and rename sex_indes column\n",
    "df_spark =df_spark.drop('Sex').withColumnRenamed('Sex_index', 'Sex')\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0adbc8d8-f3cd-40b5-a49e-6152d14a6ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|Independent Feature|  Salary|\n",
      "+-------------------+--------+\n",
      "|     [22.0,2.0,0.0]| 20000.0|\n",
      "|    [34.0,12.0,0.0]|100000.0|\n",
      "|    [54.0,22.0,0.0]|200000.0|\n",
      "|     [27.0,5.0,0.0]| 40000.0|\n",
      "|    [39.0,12.0,0.0]| 50000.0|\n",
      "|     [26.0,4.0,1.0]| 30000.0|\n",
      "|    [36.0,13.0,0.0]| 80000.0|\n",
      "|     [28.0,6.0,1.0]| 47000.0|\n",
      "+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## In Spark we have to group the independent features into single column. We do this with Vector Assembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "feature_group = VectorAssembler(\n",
    "    inputCols=['Age', 'Experience', 'Sex'],\n",
    "    outputCol=\"Independent Feature\"\n",
    ")\n",
    "\n",
    "training = feature_group.transform(df_spark)\n",
    "\n",
    "# Now we need only 2 columns 1 independent feature and other feature we need to predict\n",
    "training = training.select([\"Independent Feature\", \"Salary\"])\n",
    "\n",
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6456b9f1-ef9b-40b6-bf25-8ae7937961c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have data, lets do Train and test split\n",
    "train_data, test_data = training.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aa10cdf1-328d-4882-a6d2-8f07cd4485d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1223.3502538061841,3944.162436549359,38.07106599051356]\n",
      "-14289.340101504273\n"
     ]
    }
   ],
   "source": [
    "# Now run Linear Regressiuon\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "regressor = LinearRegression(featuresCol=\"Independent Feature\", labelCol=\"Salary\").fit(train_data)\n",
    "\n",
    "# We can see Coeficient for the Regressor\n",
    "print(regressor.coefficients)\n",
    "\n",
    "# We can see Intercepts of Regressor\n",
    "print(regressor.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2e966cd-d1e3-445c-b4a6-ceaff5de295a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+------------------+\n",
      "|Independent Feature|  Salary|        prediction|\n",
      "+-------------------+--------+------------------+\n",
      "|    [34.0,12.0,0.0]|100000.0| 74634.51776649829|\n",
      "|    [39.0,12.0,0.0]| 50000.0| 80751.26903552921|\n",
      "|    [54.0,22.0,0.0]|200000.0|138543.14720811558|\n",
      "+-------------------+--------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Lets evaluate on test data\n",
    "test_results = regressor.evaluate(test_data)\n",
    "test_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecaa6de-5415-4a85-9c14-56524c1d6c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
